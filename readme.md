## Merito
### Библиотека алгоритмов и моделей анализа резюме и вакансий с помощью машинного обучения

![](images/logo.png)
**Реализовано несколько программных модулей, а именно:**

##### Основные (по критериям поставленной задачи):
1. Автоматическое определение профессии по резюме (задача классификации резюме);
2. Автоматическое определение ожидаемой зарплаты по вакансии;
3. Создание автоматического алгоритма для преобразования списка профессий в иерархический каталог сфер и подсфер;
4. Автоматическое исправление ошибок в названиях профессий и определение сферы и подсферы на основе алгоритма из п.3;
##### Вспомогательные
1. Универсальная модель векторизации разных частей текстов резюме и вакансий;
2. Модуль полу-автоматизированного парсинга сайта hh.ru для обогащения данными;
3. Модель классификации основных сфер деятельности (19 классов, созданных на основе классификации hh.ru)

### ПРЕДВАРИТЕЛЬНАЯ УСТАНОВКА
1. Установите зависимости
```pip install -r requirements.txt```
2. (Опционально) скачайте все модели и переместите их в папку merito/models. Можно не скачивать, и они автоматически подтянутся при первом запуске модулей.
Список весов (в случае какой-либо ошибки потери весов):
   - [классификатор сфер](https://disk.yandex.ru/d/x4X4lYMdc-ZWqA)
   - [генераторы текстовых эмбеддингов](https://disk.yandex.ru/d/efUr02dykHDV8g)
   
### Определение сферы по резюме
Пример использования:  
```python
from merito.sphere_classifier import get_predict_for_resume
test_res = pd.read_csv("TEST_RES.csv")
test_res["job_title"] = get_predict_for_resume(test_res)
```

Для решения была выбрана идея генерации векторных признаков из каждой составной части резюме с помощью w2v модели, обученной следующим образом:
к каждой части резюме (достижениях, требованиях, компаниях) добавлялась сфера, затем обучался w2v с большим окном. Гипотеза в том, что обученный таким образом w2v учился репрезентовать пространство признаков на пространство сфер.

![](images/w2v.png)

За счет обучения на более узком домене данных модели после обучения достаточно хорошо обобщили семантические закономерности используемого корпуса.
Также для получения частотного представления текстов использовался алгоритм tfidf.
Описанные признаки позволили достичь следующей **точности на валидационной выборке**:  
**f1_score = 57.47 % (job classification)**

Обученные модели получились очень универсальными (особенно, векторизирующая признак demands), поэтому она применялась в других задачах в рамках библиотеки и может применяться для чего-либо в дальнейшем.
Модели (как векторизации, так и классификатор) можно дообучить в приложенным ноутбуке


### Определение зарплатных ожиданий
Пример использования:
```python
from merito.vacancy_predictor import predict_salary_by_vacancy
test_sal = pd.read_csv("TEST_SAL.csv")
test_sal["salary"] = predict_salary_by_vacancy(test_sal)
```
Для решения использовался регрессионный катбуст, обученный на большом количестве дополнительно сгенерированных признаков. Текстовые столбцы также использовался: объединялись в один текст, который векторизовывался с помощью tf-idf.  
Для генерации признаков используется конфиг SALARY_PREPROC_CONFIG.pickle, который можно менять и перенастраивать в зависимости от обучения на тех или иных данных, изучить, как генерируется он и остальные признаки, можно в приложенном ноутбуке.
Описанный подход позволил достичь следующей **точности на валидационной выборке:**
**metric = max(0, 1 - RMSE(salary predictor) / 33000) = 0.52**



### Классификация крупных сфер
Т.к. в рамках решаемой задачи классификации сфер по тексту резюме была предоставленна не самая качественная разметка, было бы эффективно иметь какую-то другую разметку с похожей задачей, на которой можно было бы предобучить модель для извлечения ещё более продвинутых признаков. Поэтому был предложен следующий способ:  
На сайте hh.ru, одном из самых крупных сервисов для соискателей и работодателей, существует открытое API, а также внутренняя разметка каждого резюме. Был разработан парсер резюме и их проф. сфер с hh.ru, на которых затем обучался w2v также, как для задачи определения сфер по резюме. Затем, на эмбеддингах был обучен алгоритм k-ближайших соседей (из-за большого кол-ва семплов он работал даже эффективнее, чем катбуст).  
Получилась следующая точность:  
**accuracy = 0.79** 

Получившуюся модель и векторизатор можно использовать как один из способов структуризации названий профессий (об этом пойдёт речь далее). Также, много применений можно найти и разработанному парсеру.


### Исправление ошибок в написании профессий
Пример использования:

```python
from merito.job_title_correction import text_correction
job = ["дврник", "дизайнер", "старший геолог", "геолог нефтяник", "свинопас", "экномист"]
for j in job:
    res = text_correction(j)
    print("Исходное название:", j, "| Отредактированное:", res[0], "| Сфера:", res[1][0], "| Подсфера:", res[1][1])

    
#Исходное название: дврник | Отредактированное: дворник | Сфера: Рабочий персонал | Подсфера: дворник
#Исходное название: дизайнер | Отредактированное: дизайнер | Сфера: Искусство, развлечения, масс-медиа | Подсфера: дизайнер
#Исходное название: старший геолог | Отредактированное: старший геолог | Сфера: Добыча сырья | Подсфера: геолог
#Исходное название: геолог нефтяник | Отредактированное: геолог нефтяник | Сфера: Добыча сырья | Подсфера: геолог
#Исходное название: свинопас | Отредактированное: свинопас | Сфера: Искусство, развлечения, масс-медиа | Подсфера: свинопас
#Исходное название: экномист | Отредактированное: экономист | Сфера: Бухгалтерия, управленческий учет, финансы предприятия | Подсфера: экономист
```
где text_correction возвращает отредактированное значение профессии, а также сферу и подсферу, к которым она принадлежит (на основе сгенерированного структурированного списка профессий) 

Для исправления ошибок в написании профессий использовалась библиотека language_tool_python, поддерживающая русский язык. Но для повышения её эффективности, а также возможности масштабирования был разработан ещё один алгоритм, работающий поверх первой модели: предварительно был сгенерирован синтетический набор данных, содержащий правильные и неправильные правописания самых распространенных названий сфер (брался job_title из задачи классификации резюме). Затем, по этому словарю явно проверялись и исправлялись найденные ошибки. Подход простой, но эффективный и хорошо масштабируемый: в дальнейшем мы можем создать более продвинутый набор данных для корреции, опираясь на статистические [правила](https://github.com/ai-forever/sage) и расширить словарь, а также юзать менее тривиальные подходы, например, считать попарные расстояния.

### Структуризация названий профессий
На основе всех предыдущих подходов был разработан алгоритм структуризации названий профессий. Работает он следующим образом:  
1. Все работы классифицируются на сферы;  
2. Внутри каждой сферы все работы кластеризируются, очищаются от выбросов, для каждого кластера генерируется на основе самых частотных слов его названия.
3. Названия приводятся в правильную форму написания с помощью предыдущей модели и кластеризируются ещё раз.

Таким образом удалось снизить количество названий работ с **1.1 млн'а до 5100**!  
Посмотрев на табличку со сгенерированными сферами и названиями работ можно [тут](https://disk.yandex.ru/d/XMvY_A2TZDFBjA)  
Подход получился довольно длительным по времени (порядка 2 часов на 1.1 млн семплов), но эффективным и масштабируемым на новые данные. 


### Дополнительно
Также реализован парсер резюме с сайта headhunter, работающий в полуручном режиме (нужно сгенерировать ссылку на страницу с резюме, скопировать её и вставить в код). Также для него нужно установить selenium:
```pip install selenium```  
Реализовано в отдельном модуле hh_parser.  
